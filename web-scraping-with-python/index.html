<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Web Scraping with Python | Tom Ordonez</title>
<meta name="generator" content="Jekyll v4.1.0" />
<meta property="og:title" content="Web Scraping with Python" />
<meta name="author" content="Tom Ordonez" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This is a tutorial on web scraping with Python. Learn to scrape websites with Python and BeautifulSoup." />
<meta property="og:description" content="This is a tutorial on web scraping with Python. Learn to scrape websites with Python and BeautifulSoup." />
<link rel="canonical" href="https://www.tomordonez.com/web-scraping-with-python/" />
<meta property="og:url" content="https://www.tomordonez.com/web-scraping-with-python/" />
<meta property="og:site_name" content="Tom Ordonez" />
<meta property="og:image" content="https://www.tomordonez.com/assets/images/sticky.gif" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-12-09T00:00:00-05:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://www.tomordonez.com/assets/images/sticky.gif" />
<meta property="twitter:title" content="Web Scraping with Python" />
<script type="application/ld+json">
{"@type":"BlogPosting","image":"https://www.tomordonez.com/assets/images/sticky.gif","headline":"Web Scraping with Python","dateModified":"2018-12-09T00:00:00-05:00","datePublished":"2018-12-09T00:00:00-05:00","url":"https://www.tomordonez.com/web-scraping-with-python/","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.tomordonez.com/web-scraping-with-python/"},"author":{"@type":"Person","name":"Tom Ordonez"},"description":"This is a tutorial on web scraping with Python. Learn to scrape websites with Python and BeautifulSoup.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://www.tomordonez.com/feed.xml" title="Tom Ordonez" /><link rel="apple-touch-icon" sizes="180x180" href="/assets/fav/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/fav/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/fav/favicon-16x16.png">
  <link rel="manifest" href="/assets/fav/site.webmanifest">
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Tom Ordonez</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about.html">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Web Scraping with Python</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2018-12-09T00:00:00-05:00" itemprop="datePublished">Dec 9, 2018
      </time>• <span>

22 min read

</span>
    </p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>This is a tutorial on web scraping with Python. Learn to scrape websites with Python and BeautifulSoup.</p>

<p><img src="/assets/images/scraping_one_page_log_file.gif" alt="Scraping one page log file" /></p>

<ol>
  <li>Setup web scraping with Python.</li>
  <li>Web scraping target and expected result.</li>
  <li>Setup logging in Python.</li>
  <li>Setup BeautifulSoup and export to CSV.</li>
  <li>Scrape one page.</li>
  <li>Scrape multiple pages.</li>
</ol>

<h2 id="to-scrape-or-not-to-scrape">To scrape or not to scrape</h2>

<p>There are tools with a user interface that allow you to point to content on a page and they scrape everything for you.</p>

<p>There is also the question of scraping or not. Can you easily copy/paste the content and modify it with Excel? Or with a text editor like Sublime Text?</p>

<p>While some tools can scrape things for you, sometimes they are hard to customize, or you have to pay for additional features.</p>

<p>This tutorial assumes that you want the freedom to scrape anything you want and customize the tool however you think is best for your needs.</p>

<h2 id="1-setup-web-scraping-with-python">1. Setup web scraping with Python.</h2>

<p>For this tutorial on web scraping I am using <code class="language-plaintext highlighter-rouge">Python 3</code>. There are a lot of tutorials online on how to install Python 3.</p>

<p>If you are new to Python. This tutorial might not be the best first step for you. Here are some good resources:</p>

<ul>
  <li><a href="https://www.python.org/">Official Python Docs</a></li>
  <li><a href="https://www.coursera.org/specializations/python">Coursera Python for Everybody</a></li>
</ul>

<p>I am also using a virtual environment with <code class="language-plaintext highlighter-rouge">miniconda</code></p>

<ul>
  <li><a href="../install-miniconda-linux">Install Miniconda</a></li>
</ul>

<p>If you are not familiar with Unix commands. Here are some resources:</p>

<ul>
  <li>Strongly recommend a book called “Unix for the Beginning Mage”. You can download it online.</li>
  <li>You can practice using this interactive shell on the browser: <code class="language-plaintext highlighter-rouge">https://www.learnshell.org/</code>.</li>
</ul>

<p>I am using Linux Fedora. The output of the commands you see in this tutorial might be different than yours.</p>

<p>Once you have <code class="language-plaintext highlighter-rouge">Python3</code> and <code class="language-plaintext highlighter-rouge">miniconda</code> installed then you can setup a virtual environment like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ conda create --name your-project
</code></pre></div></div>

<p>Activate:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ conda activate your-project
</code></pre></div></div>

<p>Go back to <code class="language-plaintext highlighter-rouge">base</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ conda activate
</code></pre></div></div>

<h2 id="2-web-scraping-target-and-expected-result">2. Web scraping target and expected result.</h2>

<p>If you made it to this point. It is downhill from here…that was a joke. It’s not :)</p>

<p>Unless you have some experience in Python. Then this should be easy.</p>

<p>What do you want to scrape? A page or multiple pages? What output do you want?</p>

<p>For this tutorial we are going to scrape speakers from a conference and the output is a CSV file with data about these speakers.</p>

<p><img src="/assets/images/ces_speakers.gif" alt="CES Speakers" /></p>

<p>Let’s open the first speaker in another tab to see what content is there:</p>

<ul>
  <li>Name of speaker</li>
  <li>Title</li>
  <li>Company</li>
  <li>Bio</li>
</ul>

<h2 id="scraping-metadata">Scraping metadata</h2>

<p>What is else is there besides what we can read on the page?</p>

<p>Right click, Inspect.</p>

<p>It has <code class="language-plaintext highlighter-rouge">meta name="keywords"</code>. Do we need these? Maybe.</p>

<p><img src="/assets/images/ces_speakers_meta_keywords.jpg" alt="CES Speaker Meta Keywords" /></p>

<p>It has a <code class="language-plaintext highlighter-rouge">meta name="description"</code> with a shorter bio.</p>

<h2 id="scraping-web-content">Scraping web content</h2>

<p>The name of the speaker is under this tag:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;h1 class="global-hero__title"&gt;
</code></pre></div></div>

<p>I see a problem. The <code class="language-plaintext highlighter-rouge">title</code> and <code class="language-plaintext highlighter-rouge">company</code> are on the same sentence, separated by a comma and it is under this tag:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;h2 class="alt"&gt;Head of Studio, SoftBank Robotics&lt;/h2&gt;
</code></pre></div></div>

<p>There is no separate tag between <code class="language-plaintext highlighter-rouge">title</code> name and <code class="language-plaintext highlighter-rouge">company</code> name.</p>

<p>On the other hand, the speakers list has <code class="language-plaintext highlighter-rouge">title</code> name and <code class="language-plaintext highlighter-rouge">company</code> name on different tags.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;h4 class="speaker-title"&gt;Head of Studio&lt;/h4&gt;
&lt;h4 class="speaker-company"&gt;SoftBank Robotics&lt;/h4&gt;
</code></pre></div></div>

<p>Can I extract this content by just copy/pasting? It doesn’t seem so. The result is:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>name
title
company
name
title
company
</code></pre></div></div>

<p>There is no way of knowing how to break this into a <code class="language-plaintext highlighter-rouge">CSV</code> file but we could take the risk of following the pattern of creating a speaker row for every 3 lines. Although I don’t see how to do this without writing some code.</p>

<p>We could also scrape the Speakers page but it doesn’t have the bios. It just has:</p>

<ul>
  <li>name</li>
  <li>title</li>
  <li>company</li>
</ul>

<h2 id="to-bio-or-not-to-bio">To bio or not to bio</h2>

<p>On the speakers page we have:</p>

<ul>
  <li>name</li>
  <li>title</li>
  <li>company</li>
  <li>speaker conference url</li>
  <li>no bio</li>
  <li>Title and company are on different html tags.</li>
</ul>

<p>On each speaker page we have:</p>

<ul>
  <li>name</li>
  <li>title</li>
  <li>company</li>
  <li>bio</li>
  <li>Title and company are on the same html tag, separated by a comma.</li>
</ul>

<p>Can we scrape the title and company from the same html tag? Then do some magic (regex) to separate the data?</p>

<p>What if the title already has a comma?</p>

<p>Such as:</p>

<ul>
  <li>Name: Homer Simpson</li>
  <li>Title: Nuclear Engineer, Research</li>
  <li>Company: ACME, Inc</li>
</ul>

<p>And the html tag has this: <code class="language-plaintext highlighter-rouge">&lt;h2 class="alt"&gt;Nuclear Engineer, Research, ACME, Inc&lt;/h2&gt;</code>.</p>

<p>This would be impossible to extract if speakers have different variations of where the comma is placed to separate title and company.</p>

<p>If we only scrape the speakers page then we will miss the <code class="language-plaintext highlighter-rouge">bio</code>.</p>

<h2 id="3-setup-logging-in-python">3. Setup logging in Python.</h2>

<p>Here is a <a href="../python-logging-tutorial">Python logging tutorial</a> to get all the details.</p>

<p>We want to capture a log file when running the script. That way we can see what worked and what didn’t. You could use <code class="language-plaintext highlighter-rouge">print</code> statements but it will be hard to read the terminal output after running the script a few times.</p>

<p>For this blog post we just have to add this code towards the top:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import logging

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
fh = logging.FileHandler('output.log')
fh.setLevel(logging.DEBUG)
formatter = logging.Formatter(('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
fh.setFormatter(formatter)
logger.addHandler(fh)
</code></pre></div></div>

<p>Then <code class="language-plaintext highlighter-rouge">logger</code> can be used as this:</p>

<p>Example 1:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for url in urls:
    logger.info('Reading URL: %s', url)
</code></pre></div></div>

<p>Example 2:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>page_title = soup.find('title').text
logger.info('page title captured: %s', page_title)
</code></pre></div></div>

<p>Then we have to close the log file at the end of the script:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for handler in logger.handlers:
    handler.close()
    logger.removeHandler(handler)
</code></pre></div></div>

<h2 id="4-setup-beautifulsoup-and-export-to-csv">4. Setup BeautifulSoup and export to CSV.</h2>

<p>For both files we need to add this code:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import urllib.request, urllib.parse, urllib.error
from bs4 import BeautifulSoup as bs
import csv
</code></pre></div></div>

<p>Why use <code class="language-plaintext highlighter-rouge">urllib</code> and not <code class="language-plaintext highlighter-rouge">requests</code>? It works and I always used it. But you are free to use any other library.</p>

<p>Followed by the logging setup</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import logging

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
fh = logging.FileHandler('output.log')
fh.setLevel(logging.DEBUG)
formatter = logging.Formatter(('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
fh.setFormatter(formatter)
logger.addHandler(fh)
</code></pre></div></div>

<p>Followed by closing the logging file:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for handler in logger.handlers:
    handler.close()
    logger.removeHandler(handler)
</code></pre></div></div>

<p>In between the logging setup we need to add our code.</p>

<h2 id="setup-beautifulsoup">Setup BeautifulSoup</h2>

<p>Given a url:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>url = 'https://www.ces.tech/Conference/Speaker-Directory.aspx'
read_url = urllib.request.urlopen(url).read()
soup = bs(read_url, 'html.parser')
</code></pre></div></div>

<p>Read more about <code class="language-plaintext highlighter-rouge">BeautifulSoup</code> here:</p>

<ul>
  <li><a href="../python-lambda">Python Lambda and BeautifulSoup</a></li>
</ul>

<h2 id="export-data-to-a-csv-file">Export data to a CSV file</h2>

<p>The usual is to export the scraped data to a CSV file.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>with open('leads.csv', 'w', newline='') as csvfile:
    csvwriter = csv.writer(csvfile)
    csvwriter.writerow(['column1', 'column2', 'column3'])
</code></pre></div></div>

<p>Then after saving data into variables. Use <code class="language-plaintext highlighter-rouge">writerow</code> to save the data to the CSV file.</p>

<h2 id="5-scrape-one-page">5. Scrape one page</h2>

<p>So far we have this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import urllib.request, urllib.parse, urllib.error
from bs4 import BeautifulSoup as bs
import csv
import logging

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
fh = logging.FileHandler('output.log')
fh.setLevel(logging.DEBUG)
formatter = logging.Formatter(('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
fh.setFormatter(formatter)
logger.addHandler(fh)

with open('leads.csv', 'w', newline='') as csvfile:
    csvwriter = csv.writer(csvfile)
    csvwriter.writerow(['column1', 'column2', 'column3'])

for handler in logger.handlers:
    handler.close()
    logger.removeHandler(handler)
</code></pre></div></div>

<p>Let’s create two scripts and save this code to each:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">one_page.py</code></li>
  <li><code class="language-plaintext highlighter-rouge">many_pages.py</code></li>
</ul>

<h2 id="scrape-the-page-that-has-the-list-of-speakers">Scrape the page that has the list of speakers:</h2>

<ul>
  <li>Name</li>
  <li>Title</li>
  <li>Company</li>
  <li>Speaker conference url</li>
  <li>No bio</li>
</ul>

<p>Modify the name of the log file. From <code class="language-plaintext highlighter-rouge">output.log</code> to <code class="language-plaintext highlighter-rouge">one_page_output.log</code>.</p>

<p>Add the <code class="language-plaintext highlighter-rouge">url</code> and create a <code class="language-plaintext highlighter-rouge">BeautifulSoup</code> object.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>url = 'https://www.ces.tech/Conference/Speaker-Directory.aspx'
read_url = urllib.request.urlopen(url).read()
soup = bs(read_url, 'html.parser')
</code></pre></div></div>

<p>Then create the <code class="language-plaintext highlighter-rouge">CSV</code> file:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>with open('one_page_leads.csv', 'w', newline='') as csvfile:
    csvwriter = csv.writer(csvfile)
    csvwriter.writerow(['name', 'title', 'company', 'url'])
</code></pre></div></div>

<p>Instead of running the script multiple times to try to scrape the data. I like to work on the Python shell to see the results and then add the code to the script.</p>

<h2 id="test-scraping-using-the-shell">Test scraping using the shell:</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(env)$ python
&gt;&gt;&gt;
</code></pre></div></div>

<p>Then setup the script with <code class="language-plaintext highlighter-rouge">BeautifulSoup</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; from bs4 import BeautifulSoup as bs
&gt;&gt;&gt; import urllib.request, urllib.parse, urllib.error
&gt;&gt;&gt; url = 'https://www.ces.tech/Conference/Speaker-Directory.aspx'
&gt;&gt;&gt; urlopen =  urllib.request.urlopen(url).read()
&gt;&gt;&gt; soup = bs(urlopen, 'html.parser')
</code></pre></div></div>

<p>Now we need to Inspect the <code class="language-plaintext highlighter-rouge">HTML</code> on the page and use <code class="language-plaintext highlighter-rouge">soup</code> methods to extract the data.</p>

<p><img src="/assets/images/one_page_scrape_speaker_data.jpg" alt="One-page scrape speaker data" /></p>

<p>To view <code class="language-plaintext highlighter-rouge">soup</code> methods you can try:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; dir(soup)
</code></pre></div></div>

<p>It will show a list of all methods.</p>

<p>Get some help about a method using <code class="language-plaintext highlighter-rouge">help</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; help(soup.find)
</code></pre></div></div>

<p>It shows the following syntax:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>find(name=None, attrs={}, recursive=True, text=None, **kwargs)
</code></pre></div></div>

<p>Each speaker has an <code class="language-plaintext highlighter-rouge">HTML</code> that looks like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;aside class="speaker-photo directory small"&gt;
    &lt;a href="/conference/speaker-directory/Omar-Abdelwahed"&gt;
        &lt;picture class="head-shot" style="background-image: url('https://hubb.blob.core.windows.net/e955a157-fba9-4f75-9465-67396ae15f0e-profile/546100')"&gt;&lt;/picture&gt;
    &lt;/a&gt;
    
        &lt;a href="/conference/speaker-directory/Omar-Abdelwahed"&gt;
            &lt;h3 class="speaker-name"&gt;Omar Abdelwahed &lt;/h3&gt;
        &lt;/a&gt;
        &lt;h4 class="speaker-title"&gt;Head of Studio&lt;/h4&gt;
        &lt;h4 class="speaker-company"&gt;SoftBank Robotics&lt;/h4&gt;
    
&lt;/aside&gt;
</code></pre></div></div>

<p>The parent tag is:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;aside class="speaker-photo directory small"&gt;
</code></pre></div></div>

<p>The child tags have this content:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">&lt;h3 class="speaker-name"&gt;</code></li>
  <li><code class="language-plaintext highlighter-rouge">&lt;h4 class="speaker-title"&gt;</code></li>
  <li><code class="language-plaintext highlighter-rouge">&lt;h4 class="speaker-company"&gt;</code></li>
  <li><code class="language-plaintext highlighter-rouge">&lt;a href="/conference/speaker-directory/...</code></li>
</ul>

<p>Which correspond to <code class="language-plaintext highlighter-rouge">name</code>, <code class="language-plaintext highlighter-rouge">title</code>, <code class="language-plaintext highlighter-rouge">company</code> and <code class="language-plaintext highlighter-rouge">url</code>.</p>

<h2 id="scrape-one-name">Scrape one name</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; soup.find('h3', attrs={'class': 'speaker-name'})
</code></pre></div></div>

<p>The output is:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;h3 class="speaker-name"&gt;Omar Abdelwahed &lt;/h3&gt;
</code></pre></div></div>

<p>This is correct but we only want the text inside the tag.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; soup.find('h3', attrs={'class': 'speaker-name'}).text
'Omar Abdelwahed '
</code></pre></div></div>

<p>But this only finds one name.</p>

<h2 id="scrape-all-the-names">Scrape all the names</h2>

<p>This doesn’t work:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; soup.find_all('h3', attrs={'class': 'speaker-name'}).text
</code></pre></div></div>

<p>It has this error:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Traceback (most recent call last):
AttributeError: ResultSet object has no attribute 'text'.
You're probably treating a list of items like a single item.
Did you call find_all() when you meant to call find()?
</code></pre></div></div>

<p>Then try this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; soup.find_all('h3', attrs={'class': 'speaker-name'})
</code></pre></div></div>

<p>The output is a list of <code class="language-plaintext highlighter-rouge">soup</code> objects with the <code class="language-plaintext highlighter-rouge">&lt;h3 class="speaker-name"&gt;</code> tag and text.</p>

<h2 id="scraping-and-matching-rows">Scraping and matching rows</h2>

<p>I thought of this. We can scrape the list of names. But what about the other data that corresponds to each speaker.</p>

<p>The names could be:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>names = [name1, name2, name3, ...]
</code></pre></div></div>

<p>Then titles:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>titles = [title1, title2, title3,...]
</code></pre></div></div>

<p>But how do we join these two lists? What if the data doesn’t match?</p>

<p>We need to find the correct data structure to put all the scraped data.</p>

<h2 id="scraping-the-parent-tag">Scraping the parent tag</h2>

<p>The parent tag that has the data for each speaker is:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;aside class="speaker-photo directory small"&gt;
</code></pre></div></div>

<p>We can use this code to find the first speaker:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; soup.find('aside', attrs={'class': 'speaker-photo directory small'})

&lt;aside class="speaker-photo directory small"&gt;
&lt;a href="/conference/speaker-directory/Omar-Abdelwahed"&gt;
&lt;picture class="head-shot" style="background-image: url('https://hubb.blob.core.windows.net/e955a157-fba9-4f75-9465-67396ae15f0e-profile/546100')"&gt;&lt;/picture&gt;
&lt;/a&gt;
&lt;caption class="speaker-info"&gt;
&lt;a href="/conference/speaker-directory/Omar-Abdelwahed"&gt;
&lt;h3 class="speaker-name"&gt;Omar Abdelwahed &lt;/h3&gt;
&lt;/a&gt;
&lt;h4 class="speaker-title"&gt;Head of Studio&lt;/h4&gt;
&lt;h4 class="speaker-company"&gt;SoftBank Robotics&lt;/h4&gt;
&lt;/caption&gt;
&lt;/aside&gt;
</code></pre></div></div>

<p>Use this code to put the <code class="language-plaintext highlighter-rouge">HTML</code> content for all speakers into a list:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; soup.find_all('aside', attrs={'class': 'speaker-photo directory small'})
</code></pre></div></div>

<p>Assign to a variable:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; speakers = soup.find_all('aside', attrs={'class': 'speaker-photo directory small'})
</code></pre></div></div>

<p>Use this: <code class="language-plaintext highlighter-rouge">speakers[0]</code> to see the content of the first speaker.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;aside class="speaker-photo directory small"&gt;
&lt;a href="/conference/speaker-directory/Omar-Abdelwahed"&gt;
&lt;picture class="head-shot" style="background-image: url('https://hubb.blob.core.windows.net/e955a157-fba9-4f75-9465-67396ae15f0e-profile/546100')"&gt;&lt;/picture&gt;
&lt;/a&gt;
&lt;caption class="speaker-info"&gt;
&lt;a href="/conference/speaker-directory/Omar-Abdelwahed"&gt;
&lt;h3 class="speaker-name"&gt;Omar Abdelwahed &lt;/h3&gt;
&lt;/a&gt;
&lt;h4 class="speaker-title"&gt;Head of Studio&lt;/h4&gt;
&lt;h4 class="speaker-company"&gt;SoftBank Robotics&lt;/h4&gt;
&lt;/caption&gt;
&lt;/aside&gt;
</code></pre></div></div>

<p>Now we can get separate the data for each speaker…</p>

<p>Actually I am not sure what methods I can use. Let’s use help:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; help(speakers[0])

Help on Tag in module bs4.element object:

class Tag(PageElement)
|  Represents a found HTML tag with its attributes and contents.
|  
|  Method resolution order:
|      Tag
|      PageElement
|      builtins.object
|  
|  Methods defined here:
</code></pre></div></div>

<p>This documentation is long. Here is an extract:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|  
|  find(self, name=None, attrs={}, recursive=True, text=None, **kwargs)
|      Return only the first child of this Tag matching the given
|      criteria.
|  
|  findAll = find_all(self, name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs)
|  
|  findChild = find(self, name=None, attrs={}, recursive=True, text=None, **kwargs)
|  findChildren = find_all(self, name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs)
|  
|  find_all(self, name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs)
|      Extracts a list of Tag objects that match the given
|      criteria.  You can specify the name of the Tag and any
|      attributes you want the Tag to have.
|      
|      The value of a key-value pair in the 'attrs' map can be a
|      string, a list of strings, a regular expression object, or a
|      callable that takes a string and returns whether or not the
|      string matches for some custom definition of 'matches'. The
|      same is true of the tag name.
|  
|  get(self, key, default=None)
|      Returns the value of the 'key' attribute for the tag, or
|      the value given for 'default' if it doesn't have that
|      attribute.
|  
|  getText = get_text(self, separator='', strip=False, types=(&lt;class 'bs4.element.NavigableString'&gt;, &lt;class 'bs4.element.CData'&gt;))
|  
|  get_attribute_list(self, key, default=None)
|      The same as get(), but always returns a list.
|  get_text(self, separator='', strip=False, types=(&lt;class 'bs4.element.NavigableString'&gt;, &lt;class 'bs4.element.CData'&gt;))
|      Get all child strings, concatenated using the given separator.
|  
</code></pre></div></div>

<h2 id="scrape-the-url">Scrape the URL</h2>

<p>Here is the code to capture the URL bio from <code class="language-plaintext highlighter-rouge">speakers[0]</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; speakers[0].find('a').get('href')
'/conference/speaker-directory/Omar-Abdelwahed'
</code></pre></div></div>

<h2 id="scrape-the-name">Scrape the name</h2>

<p>This is the HTML that contains the name:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;h3 class="speaker-name"&gt;Omar Abdelwahed &lt;/h3&gt;
</code></pre></div></div>

<p>Use this code to scrape the name:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; speakers[0].find('h3', attrs={'class': 'speaker-name'}).text
'Omar Abdelwahed '
</code></pre></div></div>

<p>I see it has whitespace at the end of the string. But not sure if this is just this one or all of them. Not a big deal for now.</p>

<h2 id="scrape-the-title">Scrape the title</h2>

<p>This HTML has the title:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;h4 class="speaker-title"&gt;Head of Studio&lt;/h4&gt;
</code></pre></div></div>

<p>Use this code:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; speakers[0].find('h4', attrs={'class': 'speaker-title'}).text
'Head of Studio'
</code></pre></div></div>

<h2 id="scrape-the-company">Scrape the company</h2>

<p>This HTML has the company:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;h4 class="speaker-company"&gt;SoftBank Robotics&lt;/h4&gt;
</code></pre></div></div>

<p>Use the code:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; speakers[0].find('h4', attrs={'class': 'speaker-company'}).text
'SoftBank Robotics'
</code></pre></div></div>

<h2 id="add-this-code-to-the-script-one_pagepy">Add this code to the script <code class="language-plaintext highlighter-rouge">one_page.py</code></h2>

<p>We don’t need to use <code class="language-plaintext highlighter-rouge">speakers[0]</code> anymore. We are going to find all speakers into a list. Then use a loop to scrape the data from each speaker. Then write the row to <code class="language-plaintext highlighter-rouge">CSV</code>.</p>

<p>We are going to use exceptions in case a data value from a speaker is not found.</p>

<p>And we will add logging for each step.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import urllib.request, urllib.parse, urllib.error
from bs4 import BeautifulSoup as bs
import csv
import logging

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
fh = logging.FileHandler('one_page_output.log')
fh.setLevel(logging.DEBUG)
formatter = logging.Formatter(('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
fh.setFormatter(formatter)
logger.addHandler(fh)


url = 'https://www.ces.tech/Conference/Speaker-Directory.aspx'
read_url = urllib.request.urlopen(url).read()
soup = bs(read_url, 'html.parser')

with open('one_page_leads.csv', 'w', newline='') as csvfile:
    csvwriter = csv.writer(csvfile)
    csvwriter.writerow(['name', 'title', 'company', 'url'])

    speakers = soup.find_all('aside', attrs={'class': 'speaker-photo directory small'})
    for speaker in speakers:

        logger.info('Scraping a speaker...')
        print('Scraping a speaker...')

        try:
            url = speaker.find('a').get('href')
        except:
            logger.info('No URL found')
            url = 'Not found'

        try:
            name = speaker.find('h3', attrs={'class': 'speaker-name'}).text
        except:
            logger.info('Name not found')
            name = 'Not found'

        try:
            title = speaker.find('h4', attrs={'class': 'speaker-title'}).text
        except:
            logger.info('Title not found')
            title = 'Not found'

        try:
            company = speaker.find('h4', attrs={'class': 'speaker-company'}).text
        except:
            logger.info('Company not found')
            company = 'Not found'

        logger.info('Saving %s to CSV', name)
        csvwriter.writerow([name, title, company, url])

for handler in logger.handlers:
    handler.close()
    logger.removeHandler(handler)
</code></pre></div></div>

<h2 id="running-the-script-one_pagepy">Running the script <code class="language-plaintext highlighter-rouge">one_page.py</code></h2>

<p>Run the script with:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ python one_page.py
</code></pre></div></div>

<p>It will take a few seconds to capture the page and then it will print to the terminal:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Scraping a speaker...
Scraping a speaker...
Scraping a speaker...
Scraping a speaker...
Scraping a speaker...
...
</code></pre></div></div>

<h2 id="review-the-log-file">Review the log file</h2>

<p>We saved the log file with this name: <code class="language-plaintext highlighter-rouge">one_page_output.log</code></p>

<p><img src="/assets/images/scraping_one_page_log_file.gif" alt="Scraping one page log file" /></p>

<p>It looks like it scraped all the data.</p>

<h2 id="review-the-csv-file">Review the CSV file</h2>

<p>We named the CSV file: <code class="language-plaintext highlighter-rouge">one_page_leads.csv</code>.</p>

<p><img src="/assets/images/scraping_one_page_data.gif" alt="Scraped data into CSV" /></p>

<p>It looks good. But the dilemma continues. We don’t have the <code class="language-plaintext highlighter-rouge">bios</code>.</p>

<h2 id="6-scrape-multiple-pages">6. Scrape multiple pages.</h2>

<p>We can add more to the script if we really want the <code class="language-plaintext highlighter-rouge">bio</code> for each speaker.</p>

<p>Let’s just copy the script over to a new file: <code class="language-plaintext highlighter-rouge">many_pages.py</code>.</p>

<p>But first let’s test how to get a <code class="language-plaintext highlighter-rouge">bio</code> using the Python shell.</p>

<p>The first URL from the CSV file is this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/conference/speaker-directory/Omar-Abdelwahed
</code></pre></div></div>

<p>Go to the shell:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; from bs4 import BeautifulSoup as bs
&gt;&gt;&gt; import urllib.request, urllib.parse, urllib.error
&gt;&gt;&gt; url = 'https://www.ces.tech/conference/speaker-directory/Omar-Abdelwahed'
&gt;&gt;&gt; urlopen =  urllib.request.urlopen(url).read()
&gt;&gt;&gt; soup = bs(urlopen, 'html.parser')
</code></pre></div></div>

<p>Previously we saw that there were 2 bios.</p>

<h2 id="short-bio">Short bio</h2>

<p>This metadata has a short bio:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;meta name="description" content="Omar Abdelwahed is Head of Studio at SoftBank Robotics America where he is responsible for leading the development of robotics applications in America, and the overall user experience, globally"&gt;
</code></pre></div></div>

<p>Scrape it with:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; soup.find('meta', attrs={'name': 'description'}).get('content')

'Omar Abdelwahed is Head of Studio at SoftBank Robotics America where he is responsible for leading the development of robotics applications in America, and the overall user experience, globally'
</code></pre></div></div>

<h2 id="long-bio">Long bio</h2>

<p>This tag has a long bio:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;article class="speaker-bio"&gt;
&lt;p&gt;Omar Abdelwahed is Head of Studio at SoftBank Robotics America where he is responsible for leading the development of robotics applications in America, and the overall user experience, globally. Previously, Omar was VP of Engineering at Mighty Play, a game developer in San Francisco. Omar has over 20 years of experience as an engineer with a deep background in entertainment and technology. Omar’s career has spanned large video game publishers, retailers, startups, and his own independent work. Omar is the founder of Agent Disco, an independent mobile games developer. He is a frequent conference speaker on technology topics, including AI, robotics, data privacy, and product development.&lt;/p&gt;
&lt;div&gt;
&lt;/div&gt;
&lt;/article&gt;
</code></pre></div></div>

<p>Scrape it with:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; soup.find('article', attrs={'class': 'speaker-bio'}).find('p').text

'Omar Abdelwahed is Head of Studio at SoftBank Robotics America where he is responsible for leading the development of robotics applications in America, and the overall user experience, globally. Previously, Omar was VP of Engineering at Mighty Play, a game developer in San Francisco. Omar has over 20 years of experience as an engineer with a deep background in entertainment and technology. Omar’s career has spanned large video game publishers, retailers, startups, and his own independent work. Omar is the founder of Agent Disco, an independent mobile games developer. He is a frequent conference speaker on technology topics, including AI, robotics, data privacy, and product development.'
</code></pre></div></div>

<p>Looks like the short bio is the first sentence up to the first period. For others it might or might not be the same.</p>

<p>Maybe we should scrape both just in case.</p>

<p>I opened a few profiles and noticed some have additional data.</p>

<h2 id="linkedin-url">Linkedin URL</h2>

<p>Found that this profile:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>https://www.ces.tech/conference/speaker-directory/Charlie--Ackerman.aspx
</code></pre></div></div>

<p>Has a Linkedin URL:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;a href="https://www.linkedin.com/in/charlie-ackerman-56499013/" target="_blank" class="fab fa-linkedin"&gt;&lt;/a&gt;
</code></pre></div></div>

<p>Scrape it with:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; soup.find('a', attrs={'class': 'fab fa-linkedin'}).get('href')

'https://www.linkedin.com/in/charlie-ackerman-56499013/'
</code></pre></div></div>

<h2 id="modifying-the-script-many_pagespy">Modifying the script <code class="language-plaintext highlighter-rouge">many_pages.py</code></h2>

<p>Same setup as before but change log file name and csv file name:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import urllib.request, urllib.parse, urllib.error
from bs4 import BeautifulSoup as bs
import csv
import logging

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
fh = logging.FileHandler('many_pages_output.log')
fh.setLevel(logging.DEBUG)
formatter = logging.Formatter(('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
fh.setFormatter(formatter)
logger.addHandler(fh)

url = 'https://www.ces.tech/Conference/Speaker-Directory.aspx'
read_url = urllib.request.urlopen(url).read()
soup = bs(read_url, 'html.parser')

with open('many_pages_leads.csv', 'w', newline='') as csvfile:
    csvwriter = csv.writer(csvfile)
    csvwriter.writerow(['name', 'title', 'company', 'url'])

for handler in logger.handlers:
    handler.close()
    logger.removeHandler(handler)
</code></pre></div></div>

<p>We need to make some additional changes.</p>

<p>Once we capture each <code class="language-plaintext highlighter-rouge">URL</code> we need to scrape the data:</p>

<ul>
  <li>short bio</li>
  <li>long bio</li>
  <li>Linkedin URL</li>
</ul>

<p>Change the column names of the <code class="language-plaintext highlighter-rouge">CSV</code> file:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>with open('many_pages_leads.csv', 'w', newline='') as csvfile:
    csvwriter = csv.writer(csvfile)
    csvwriter.writerow(['name', 'title', 'company', 'url', 'short_bio', 'long_bio', 'linkedin'])
</code></pre></div></div>

<p>A scraped <code class="language-plaintext highlighter-rouge">URL</code> has this form:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/conference/speaker-directory/Omar-Abdelwahed
</code></pre></div></div>

<p>To scrape this page we need the complete <code class="language-plaintext highlighter-rouge">URL</code>. Maybe add this variable:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>root_url = 'https://www.ces.tech'
</code></pre></div></div>

<h2 id="the-final-script-is-this">The final script is this</h2>

<p>Ideally this could be broken into modules but for now this is the final script:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import urllib.request, urllib.parse, urllib.error
from bs4 import BeautifulSoup as bs
import csv
import logging

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
fh = logging.FileHandler('many_pages_output.log')
fh.setLevel(logging.DEBUG)
formatter = logging.Formatter(('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
fh.setFormatter(formatter)
logger.addHandler(fh)

root_url = 'https://www.ces.tech'

url = 'https://www.ces.tech/Conference/Speaker-Directory.aspx'
urlopen = urllib.request.urlopen(url).read()
soup = bs(urlopen, 'html.parser')

with open('many_pages_leads.csv', 'w', newline='') as csvfile:
    csvwriter = csv.writer(csvfile)
    csvwriter.writerow(['name', 'title', 'company', 'url', 'short_bio', 'long_bio', 'linkedin'])

    speakers = soup.find_all('aside', attrs={'class': 'speaker-photo directory small'})
    for speaker in speakers:

        logger.info('Scraping a speaker...')
        print('Scraping a speaker...')
        
        try:
            name = speaker.find('h3', attrs={'class': 'speaker-name'}).text
        except:
            logger.info('Name not found')
            name = 'Not found'

        try:
            title = speaker.find('h4', attrs={'class': 'speaker-title'}).text
        except:
            logger.info('Title not found')
            title = 'Not found'

        try:
            company = speaker.find('h4', attrs={'class': 'speaker-company'}).text
        except:
            logger.info('Company not found')
            company = 'Not found'
        
        try:
            url = speaker.find('a').get('href')

            url_speaker = urllib.request.urlopen(root_url + url).read()
            soup_speaker = bs(url_speaker, 'html.parser')

            # Get short bio
            try:
                short_bio = soup_speaker.find('meta', attrs={'name': 'description'}).get('content')
            except:
                logger.info('Short bio not found')
                short_bio = 'Not found'

            # Get long bio
            try:
                long_bio = soup_speaker.find('article', attrs={'class': 'speaker-bio'}).find('p').text
            except:
                logger.info('Long bio not found')
                long_bio = 'Not found'

            # Get Linkedin
            try:
                linkedin = soup_speaker.find('a', attrs={'class': 'fab fa-linkedin'}).get('href')
            except:
                logger.info('Linkedin URL not found')
                linkedin = 'Not found'

        except:
            logger.info('URL not found')
            url = 'Not found'

        logger.info('Saving %s to CSV', name)

        csvwriter.writerow([name, title, company, url, short_bio, long_bio, linkedin])

for handler in logger.handlers:
    handler.close()
    logger.removeHandler(handler)
</code></pre></div></div>

<h2 id="reviewing-results">Reviewing results</h2>

<p>You can open the log file in Sublime to see progress. Or just monitor the file size and you will see the log file increasing size.</p>

<p>Open the CSV file to see the output so far:</p>

<p><img src="/assets/images/scraping_many_pages.gif" alt="CES Speakers" /></p>

<h2 id="to-module-or-not-to-module">To module or not to module</h2>

<p>This looks like a one-time script. A sort of scrape-on-demand. Scrape a specific page and move on. Another scrape project would have a different <code class="language-plaintext highlighter-rouge">HTML</code> structure depending on what you want to scrape.</p>

<p>You could use the same setup for <code class="language-plaintext highlighter-rouge">logging</code> and <code class="language-plaintext highlighter-rouge">CSV</code> but there is room for growth if you break this into modules:</p>

<ul>
  <li>Ask for user input instead of hardcoding the URLs.</li>
  <li>Use a <code class="language-plaintext highlighter-rouge">main</code> function for the setup.</li>
  <li>Use modules for scraping.</li>
  <li>Use a random function to ease on the scraping.of hardcoding the URLs.</li>
</ul>

  </div>

  
  <div>
    <h3>Related Posts</h3>
    <ul>
    
      <li><a href="/python-lambda-beautifulsoup/">Python Lambda and BeautifulSoup</a></li>
    
      <li><a href="/python-files-os-module/">Python, Files, and OS Module</a></li>
    
      <li><a href="/python-jupyter-notebook-linux/">Python Jupyter Notebook in Linux</a></li>
    
      <li><a href="/install-miniconda-linux/">Install Miniconda on Linux</a></li>
    
      <li><a href="/make-static-website-python-github-pages/">Make a Static Website with Python and Github Pages</a></li>
    
    </ul>
  </div>
  <a class="u-url" href="/web-scraping-with-python/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Tom Ordonez</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">{&quot;name&quot;=&gt;&quot;Tom Ordonez&quot;}</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/tomordonez"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">tomordonez</span></a></li><li><a href="https://www.twitter.com/tomordonez"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">tomordonez</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>A blog about analytics, data science, software engineering, and other thoughts.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
